{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class Conv3DNet(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_channels, kernel_size, sequence_length):\n",
    "        super(Conv3DNet, self).__init__()\n",
    "        \n",
    "        self.padding = kernel_size // 2\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(input_channels, hidden_channels, kernel_size, padding=self.padding, bias=True)\n",
    "        self.conv2 = nn.Conv3d(hidden_channels, hidden_channels, kernel_size, padding=self.padding, bias=True)\n",
    "        self.conv3 = nn.Conv3d(hidden_channels, input_channels, (1, kernel_size, kernel_size), padding=self.padding, bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x\n",
    "\n",
    "def generate_data(batch_size, sequence_length, image_size, max_step_size=2):\n",
    "    directions = np.random.randint(0, 4, batch_size)  # 0: right, 1: down, 2: left, 3: up\n",
    "    \n",
    "    # Initialize all sequences to start from the central pixel\n",
    "    start_x = image_size // 2\n",
    "    start_y = image_size // 2\n",
    "    start_points = [(start_x, start_y) for _ in range(batch_size)]\n",
    "    \n",
    "    sequences = np.zeros((batch_size, 1, sequence_length, image_size, image_size))\n",
    "    \n",
    "    for b in range(batch_size):\n",
    "        x, y = start_points[b]\n",
    "        dx, dy = 0, 0\n",
    "        \n",
    "        if directions[b] == 0: dx = max_step_size\n",
    "        if directions[b] == 1: dy = max_step_size\n",
    "        if directions[b] == 2: dx = -max_step_size\n",
    "        if directions[b] == 3: dy = -max_step_size\n",
    "        \n",
    "        for t in range(sequence_length):\n",
    "            sequences[b, 0, t, y, x] = 1.0\n",
    "            x = np.clip(x + dx, 0, image_size - 1)  # No toroidal looping, clamp at edges\n",
    "            y = np.clip(y + dy, 0, image_size - 1)  # No toroidal looping, clamp at edges\n",
    "    \n",
    "    return torch.tensor(sequences, dtype=torch.float32)\n",
    "\n",
    "def save_data_to_disk(data, filename):\n",
    "    \"\"\"Save the generated data tensor to disk.\"\"\"\n",
    "    torch.save(data, filename)\n",
    "\n",
    "def load_data_from_disk(filename):\n",
    "    \"\"\"Load the data tensor from disk.\"\"\"\n",
    "    return torch.load(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "sequence_length = 8\n",
    "image_size = 16\n",
    "input_channels = 1  # Grayscale images\n",
    "hidden_channels = 64\n",
    "kernel_size = 3\n",
    "lr = 0.001\n",
    "num_epochs = 100\n",
    "print_interval = 10\n",
    "data_filename = \"training_data.pt\"\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Conv3DNet(input_channels, hidden_channels, kernel_size, sequence_length).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = generate_data(batch_size, sequence_length + 1, image_size).to(device)\n",
    "save_data_to_disk(sequences, data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jare0530\\Projects\\102423_NeuralWavefunctionCollapse\\NeuralWavefunctionCollapse\\.venv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:535: UserWarning: Using a target size (torch.Size([128, 1, 16, 16])) that is different to the input size (torch.Size([128, 1, 10, 16, 16])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.0042\n",
      "Epoch [20/100], Loss: 0.0040\n",
      "Epoch [30/100], Loss: 0.0040\n",
      "Epoch [40/100], Loss: 0.0039\n",
      "Epoch [50/100], Loss: 0.0038\n",
      "Epoch [60/100], Loss: 0.0038\n",
      "Epoch [70/100], Loss: 0.0038\n",
      "Epoch [80/100], Loss: 0.0038\n",
      "Epoch [90/100], Loss: 0.0037\n",
      "Epoch [100/100], Loss: 0.0037\n",
      "Training finished!\n"
     ]
    }
   ],
   "source": [
    "# Check if data exists on disk, otherwise generate and save\n",
    "if os.path.exists(data_filename):\n",
    "    sequences = load_data_from_disk(data_filename).to(device)\n",
    "else:\n",
    "    sequences = generate_data(batch_size, sequence_length + 1, image_size).to(device)\n",
    "    save_data_to_disk(sequences, data_filename)\n",
    "\n",
    "inputs = sequences[:, :, :sequence_length]  # First 8 frames\n",
    "targets = sequences[:, :, sequence_length]  # The 9th frame is our target\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Loss and optimization\n",
    "    loss = criterion(outputs, targets)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print updates\n",
    "    if (epoch + 1) % print_interval == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(\"Training finished!\")\n",
    "# Save the trained model to disk\n",
    "torch.save(model.state_dict(), \"model_weights.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 8 is out of bounds for dimension 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m test_sequences \u001b[39m=\u001b[39m generate_data(test_batch_size, sequence_length\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, image_size)\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     34\u001b[0m inputs \u001b[39m=\u001b[39m test_sequences[:, :sequence_length]\n\u001b[1;32m---> 35\u001b[0m targets \u001b[39m=\u001b[39m test_sequences[:, sequence_length]\n\u001b[0;32m     37\u001b[0m \u001b[39m# Predict the next frame using the model\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "\u001b[1;31mIndexError\u001b[0m: index 8 is out of bounds for dimension 1 with size 1"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_images(sequence, predicted, image_size=32):\n",
    "    ''' Visualize sequences of images and the predicted next frame. '''\n",
    "    seq_length = sequence.shape[1]\n",
    "    \n",
    "    for idx in range(sequence.shape[0]):  # Loop over the batch\n",
    "        fig, axarr = plt.subplots(1, seq_length+1, figsize=(20, 2))\n",
    "        \n",
    "        for t in range(seq_length):\n",
    "            axarr[t].imshow(sequence[idx, t, 0].cpu().numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "            axarr[t].axis('off')\n",
    "            \n",
    "            if t == 0:\n",
    "                axarr[t].set_title(\"Input Sequence\")\n",
    "            \n",
    "        axarr[seq_length].imshow(predicted[idx, 0].cpu().detach().numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "        axarr[seq_length].axis('off')\n",
    "        axarr[seq_length].set_title(\"Predicted\")\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Load the model from disk\n",
    "model_path = \"model_weights.pt\"\n",
    "model = Conv3DNet(input_channels, hidden_channels, kernel_size, sequence_length).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Generate some test sequences\n",
    "test_batch_size = 5\n",
    "test_sequences = generate_data(test_batch_size, sequence_length+1, image_size).to(device)\n",
    "inputs = test_sequences[:, :, :sequence_length, :, :]\n",
    "targets = test_sequences[:, :, sequence_length, :, :]\n",
    "\n",
    "\n",
    "# Predict the next frame using the model\n",
    "with torch.no_grad():\n",
    "    predictions = model(inputs)\n",
    "\n",
    "# Plot the sequences and the predicted frames\n",
    "plot_images(inputs, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
